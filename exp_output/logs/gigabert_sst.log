Evaluating perturbation model on test set...

Perturbation p = 0.00000: Test avg accuracy = 0.83716 +- 0.00000, f1_acc = 0.83716 +- 0.00000,  avg loss: 0.39614
Perturbation p = 0.05000: Test avg accuracy = 0.76216 +- 0.06575, f1_acc = 0.76216 +- 0.06575,  avg loss: 0.48900
Perturbation p = 0.10000: Test avg accuracy = 0.64599 +- 0.10737, f1_acc = 0.64599 +- 0.10737,  avg loss: 0.65808
Perturbation p = 0.15000: Test avg accuracy = 0.65711 +- 0.12297, f1_acc = 0.65711 +- 0.12297,  avg loss: 0.60916
Perturbation p = 0.20000: Test avg accuracy = 0.66571 +- 0.12279, f1_acc = 0.66571 +- 0.12279,  avg loss: 0.65335
Perturbation p = 0.25000: Test avg accuracy = 0.52672 +- 0.06968, f1_acc = 0.52672 +- 0.06968,  avg loss: 0.68782
Perturbation p = 0.30000: Test avg accuracy = 0.50229 +- 0.02248, f1_acc = 0.50229 +- 0.02248,  avg loss: 0.76694
Perturbation p = 0.35000: Test avg accuracy = 0.49599 +- 0.01058, f1_acc = 0.49599 +- 0.01058,  avg loss: 0.72859
Perturbation p = 0.40000: Test avg accuracy = 0.49358 +- 0.00826, f1_acc = 0.49358 +- 0.00826,  avg loss: 0.73116
Perturbation p = 0.45000: Test avg accuracy = 0.51812 +- 0.05768, f1_acc = 0.51812 +- 0.05768,  avg loss: 0.69368
======= Done perturbation eval========
{
  "aggregated": 0.8371559633027523,
  "sst": {
    "loss": 0.39613537596804754,
    "metrics": {
      "major": 0.8371559633027523,
      "minor": {
        "acc": 0.8371559633027523
      }
    }
  }
}
